{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "832ff470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import trange\n",
    "import time\n",
    "\n",
    "from bound_propagation import BoundModelFactory, HyperRectangle\n",
    "\n",
    "\n",
    "class IBPNet(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(IBPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 28*28))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d3326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_transform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Lambda(torch.flatten)\n",
    "    ])\n",
    "    target_transform = transforms.Compose([])\n",
    "    return transform, target_transform\n",
    "\n",
    "\n",
    "def adversarial_logit(y_hat, y):\n",
    "    \"\"\"Compute adversarial logits by taking upper bounds for incorrect classes\n",
    "    and lower bounds for the correct class.\"\"\"\n",
    "    batch_size = y.size(0)\n",
    "    classes = torch.arange(10, device=y.device).unsqueeze(0).expand(batch_size, -1)\n",
    "    mask = (classes == y.unsqueeze(-1)).to(dtype=y_hat.lower.dtype)\n",
    "    \n",
    "    # Take upper bound for logit of all but the correct class where you take the lower bound\n",
    "    adversarial_logit = (1 - mask) * y_hat.upper + mask * y_hat.lower\n",
    "    return adversarial_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b802534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ibp(net, device, num_epochs=100, epsilon_target=0.1):\n",
    "    \"\"\"Train network with IBP robustness training following the paper's procedure.\n",
    "    \n",
    "    The training uses:\n",
    "    - Curriculum learning with scheduled κ (1.0 → 0.5) and ε (0 → ε_target)\n",
    "    - Combined loss: κ·CE(z_K, y) + (1-κ)·CE(ẑ_K(ε), y)\n",
    "    - Linear warmup and ramp-up schedules as in paper Appendix A\n",
    "    \"\"\"\n",
    "    print('[IBP TRAINING - Following Paper Protocol]')\n",
    "    \n",
    "    transform, target_transform = construct_transform()\n",
    "    train_data = datasets.FashionMNIST('./fashion_data', train=True, download=True,\n",
    "                                       transform=transform, target_transform=target_transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=100, shuffle=True, num_workers=4)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Training schedule parameters (from paper Appendix A)\n",
    "    total_steps = num_epochs * len(train_loader)\n",
    "    warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
    "    rampup_steps = int(0.5 * total_steps)  # 50% ramp-up for epsilon\n",
    "    \n",
    "    # Learning rate decay schedule\n",
    "    lr_decay_steps = [int(0.6 * total_steps), int(0.9 * total_steps)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    current_step = 0\n",
    "    \n",
    "    for epoch in trange(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_ce = 0.0\n",
    "        running_robust = 0.0\n",
    "        \n",
    "        for batch_idx, (X, y) in enumerate(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Learning rate schedule\n",
    "            if current_step == lr_decay_steps[0] or current_step == lr_decay_steps[1]:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 0.1\n",
    "            \n",
    "            # Linear warmup for learning rate\n",
    "            if current_step < warmup_steps:\n",
    "                lr_scale = current_step / warmup_steps\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = 1e-3 * lr_scale\n",
    "            \n",
    "            # Compute schedule values (linear ramp)\n",
    "            # κ: from 1.0 to 0.5 over full training\n",
    "            k = max(1.0 - 0.5 * (current_step / total_steps), 0.5)\n",
    "            \n",
    "            # ε: from 0 to ε_target over rampup period\n",
    "            if current_step < rampup_steps:\n",
    "                eps_train = epsilon_target * (current_step / rampup_steps)\n",
    "            else:\n",
    "                eps_train = epsilon_target\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Standard prediction and CE loss\n",
    "            y_hat = net(X)\n",
    "            ce_loss = criterion(y_hat, y)\n",
    "            \n",
    "            # IBP bound propagation and robustness loss\n",
    "            bounds = net.ibp(HyperRectangle.from_eps(X, eps_train))\n",
    "            adv_logit = adversarial_logit(bounds, y)\n",
    "            robust_loss = criterion(adv_logit, y)\n",
    "            \n",
    "            # Combined loss (Eq. 12 from paper)\n",
    "            loss = k * ce_loss + (1 - k) * robust_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_ce += ce_loss.item()\n",
    "            running_robust += robust_loss.item()\n",
    "            current_step += 1\n",
    "            \n",
    "            if batch_idx % 50 == 49:\n",
    "                print(f'Epoch [{epoch+1:3d}/{num_epochs}], Step [{batch_idx+1:3d}], '\n",
    "                      f'Loss: {running_loss/50:.4f}, CE: {running_ce/50:.4f}, '\n",
    "                      f'Robust: {running_robust/50:.4f}, ε: {eps_train:.4f}, κ: {k:.3f}')\n",
    "                running_loss = 0.0\n",
    "                running_ce = 0.0\n",
    "                running_robust = 0.0\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f'IBP Training completed in {training_time:.2f} seconds')\n",
    "    return training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1feee09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_standard(net, device, num_epochs=100):\n",
    "    \"\"\"Standard training with cross-entropy loss for comparison.\"\"\"\n",
    "    print('[STANDARD TRAINING]')\n",
    "    \n",
    "    transform, target_transform = construct_transform()\n",
    "    train_data = datasets.FashionMNIST('./fashion_data', train=True, download=True,\n",
    "                                       transform=transform, target_transform=target_transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=100, shuffle=True, num_workers=4)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_steps = num_epochs * len(train_loader)\n",
    "    lr_decay_steps = [int(0.6 * total_steps), int(0.9 * total_steps)]\n",
    "    current_step = 0\n",
    "    \n",
    "    for epoch in trange(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (X, y) in enumerate(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Learning rate decay schedule\n",
    "            if current_step == lr_decay_steps[0] or current_step == lr_decay_steps[1]:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 0.1\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            current_step += 1\n",
    "            \n",
    "            if batch_idx % 50 == 49:\n",
    "                print(f'Epoch [{epoch+1:3d}/{num_epochs}], Step [{batch_idx+1:3d}], Loss: {running_loss/50:.4f}')\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f'Standard Training completed in {training_time:.2f} seconds')\n",
    "    return training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7eb26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_standard_accuracy(net, device):\n",
    "    \"\"\"Evaluate standard accuracy on test set.\"\"\"\n",
    "    print('[STANDARD ACCURACY TEST]')\n",
    "    \n",
    "    transform, target_transform = construct_transform()\n",
    "    test_data = datasets.FashionMNIST('./fashion_data', train=False, download=True,\n",
    "                                      transform=transform, target_transform=target_transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = net(X)\n",
    "        predicted = torch.argmax(y_hat, dim=1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Standard Accuracy: {accuracy:.4f}')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def test_robust_accuracy_pgd(net, device, epsilon=0.1, num_steps=20, step_size=None):\n",
    "    \"\"\"Evaluate robust accuracy against PGD attack.\"\"\"\n",
    "    print(f'[ROBUST ACCURACY TEST - PGD ε={epsilon}]')\n",
    "    \n",
    "    if step_size is None:\n",
    "        step_size = epsilon / 4\n",
    "    \n",
    "    transform, target_transform = construct_transform()\n",
    "    test_data = datasets.FashionMNIST('./fashion_data', train=False, download=True,\n",
    "                                      transform=transform, target_transform=target_transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # PGD attack\n",
    "        X_adv = X.clone() + torch.empty_like(X).uniform_(-epsilon, epsilon)\n",
    "        X_adv = torch.clamp(X_adv, 0, 1)\n",
    "        X_adv.requires_grad = True\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            with torch.enable_grad():\n",
    "                y_hat = net(X_adv)\n",
    "                loss = F.cross_entropy(y_hat, y)\n",
    "                grad = torch.autograd.grad(loss, X_adv)[0]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                X_adv.data = X_adv + step_size * grad.sign()\n",
    "                X_adv.data = torch.clamp(X_adv, X - epsilon, X + epsilon)\n",
    "                X_adv.data = torch.clamp(X_adv, 0, 1)\n",
    "            \n",
    "            X_adv.requires_grad_(True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_hat = net(X_adv)\n",
    "            predicted = torch.argmax(y_hat, dim=1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Robust Accuracy (PGD ε={epsilon}): {accuracy:.4f}')\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc90f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "============================================================\n",
      "STANDARD TRAINING\n",
      "============================================================\n",
      "[STANDARD TRAINING]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/20], Step [ 50], Loss: 1.7397\n",
      "Epoch [  1/20], Step [100], Loss: 0.8435\n",
      "Epoch [  1/20], Step [150], Loss: 0.7270\n",
      "Epoch [  1/20], Step [200], Loss: 0.6403\n",
      "Epoch [  1/20], Step [250], Loss: 0.6333\n",
      "Epoch [  1/20], Step [300], Loss: 0.5525\n",
      "Epoch [  1/20], Step [350], Loss: 0.5439\n",
      "Epoch [  1/20], Step [400], Loss: 0.5287\n",
      "Epoch [  1/20], Step [450], Loss: 0.5286\n",
      "Epoch [  1/20], Step [500], Loss: 0.5302\n",
      "Epoch [  1/20], Step [550], Loss: 0.4902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:03<01:04,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/20], Step [600], Loss: 0.4894\n",
      "Epoch [  2/20], Step [ 50], Loss: 0.4708\n",
      "Epoch [  2/20], Step [100], Loss: 0.4765\n",
      "Epoch [  2/20], Step [150], Loss: 0.4739\n",
      "Epoch [  2/20], Step [200], Loss: 0.4496\n",
      "Epoch [  2/20], Step [250], Loss: 0.4498\n",
      "Epoch [  2/20], Step [300], Loss: 0.4389\n",
      "Epoch [  2/20], Step [350], Loss: 0.4293\n",
      "Epoch [  2/20], Step [400], Loss: 0.4422\n",
      "Epoch [  2/20], Step [450], Loss: 0.4223\n",
      "Epoch [  2/20], Step [500], Loss: 0.4306\n",
      "Epoch [  2/20], Step [550], Loss: 0.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:06<01:00,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  2/20], Step [600], Loss: 0.4279\n",
      "Epoch [  3/20], Step [ 50], Loss: 0.4173\n",
      "Epoch [  3/20], Step [100], Loss: 0.4084\n",
      "Epoch [  3/20], Step [150], Loss: 0.3923\n",
      "Epoch [  3/20], Step [200], Loss: 0.4225\n",
      "Epoch [  3/20], Step [250], Loss: 0.4013\n",
      "Epoch [  3/20], Step [300], Loss: 0.4058\n",
      "Epoch [  3/20], Step [350], Loss: 0.3935\n",
      "Epoch [  3/20], Step [400], Loss: 0.4016\n",
      "Epoch [  3/20], Step [450], Loss: 0.3936\n",
      "Epoch [  3/20], Step [500], Loss: 0.3733\n",
      "Epoch [  3/20], Step [550], Loss: 0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:10<00:56,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  3/20], Step [600], Loss: 0.3831\n",
      "Epoch [  4/20], Step [ 50], Loss: 0.3716\n",
      "Epoch [  4/20], Step [100], Loss: 0.3783\n",
      "Epoch [  4/20], Step [150], Loss: 0.3482\n",
      "Epoch [  4/20], Step [200], Loss: 0.3796\n",
      "Epoch [  4/20], Step [250], Loss: 0.3736\n",
      "Epoch [  4/20], Step [300], Loss: 0.3708\n",
      "Epoch [  4/20], Step [350], Loss: 0.3663\n",
      "Epoch [  4/20], Step [400], Loss: 0.3682\n",
      "Epoch [  4/20], Step [450], Loss: 0.3542\n",
      "Epoch [  4/20], Step [500], Loss: 0.3787\n",
      "Epoch [  4/20], Step [550], Loss: 0.3760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:13<00:54,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  4/20], Step [600], Loss: 0.3579\n",
      "Epoch [  5/20], Step [ 50], Loss: 0.3674\n",
      "Epoch [  5/20], Step [100], Loss: 0.3486\n",
      "Epoch [  5/20], Step [150], Loss: 0.3466\n",
      "Epoch [  5/20], Step [200], Loss: 0.3615\n",
      "Epoch [  5/20], Step [250], Loss: 0.3586\n",
      "Epoch [  5/20], Step [300], Loss: 0.3425\n",
      "Epoch [  5/20], Step [350], Loss: 0.3394\n",
      "Epoch [  5/20], Step [400], Loss: 0.3428\n",
      "Epoch [  5/20], Step [450], Loss: 0.3374\n",
      "Epoch [  5/20], Step [500], Loss: 0.3421\n",
      "Epoch [  5/20], Step [550], Loss: 0.3354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:16<00:50,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  5/20], Step [600], Loss: 0.3454\n",
      "Epoch [  6/20], Step [ 50], Loss: 0.3293\n",
      "Epoch [  6/20], Step [100], Loss: 0.3269\n",
      "Epoch [  6/20], Step [150], Loss: 0.3356\n",
      "Epoch [  6/20], Step [200], Loss: 0.3431\n",
      "Epoch [  6/20], Step [250], Loss: 0.3501\n",
      "Epoch [  6/20], Step [300], Loss: 0.3448\n",
      "Epoch [  6/20], Step [350], Loss: 0.3457\n",
      "Epoch [  6/20], Step [400], Loss: 0.3195\n",
      "Epoch [  6/20], Step [450], Loss: 0.3110\n",
      "Epoch [  6/20], Step [500], Loss: 0.3097\n",
      "Epoch [  6/20], Step [550], Loss: 0.3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:20<00:47,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  6/20], Step [600], Loss: 0.3344\n",
      "Epoch [  7/20], Step [ 50], Loss: 0.3007\n",
      "Epoch [  7/20], Step [100], Loss: 0.3236\n",
      "Epoch [  7/20], Step [150], Loss: 0.3369\n",
      "Epoch [  7/20], Step [200], Loss: 0.3076\n",
      "Epoch [  7/20], Step [250], Loss: 0.3230\n",
      "Epoch [  7/20], Step [300], Loss: 0.3067\n",
      "Epoch [  7/20], Step [350], Loss: 0.3175\n",
      "Epoch [  7/20], Step [400], Loss: 0.3018\n",
      "Epoch [  7/20], Step [450], Loss: 0.3161\n",
      "Epoch [  7/20], Step [500], Loss: 0.3321\n",
      "Epoch [  7/20], Step [550], Loss: 0.3328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:23<00:44,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  7/20], Step [600], Loss: 0.3136\n",
      "Epoch [  8/20], Step [ 50], Loss: 0.3219\n",
      "Epoch [  8/20], Step [100], Loss: 0.3048\n",
      "Epoch [  8/20], Step [150], Loss: 0.3110\n",
      "Epoch [  8/20], Step [200], Loss: 0.3013\n",
      "Epoch [  8/20], Step [250], Loss: 0.3007\n",
      "Epoch [  8/20], Step [300], Loss: 0.3028\n",
      "Epoch [  8/20], Step [350], Loss: 0.3121\n",
      "Epoch [  8/20], Step [400], Loss: 0.3129\n",
      "Epoch [  8/20], Step [450], Loss: 0.3011\n",
      "Epoch [  8/20], Step [500], Loss: 0.3025\n",
      "Epoch [  8/20], Step [550], Loss: 0.3195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:27<00:40,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  8/20], Step [600], Loss: 0.3043\n",
      "Epoch [  9/20], Step [ 50], Loss: 0.3000\n",
      "Epoch [  9/20], Step [100], Loss: 0.3043\n",
      "Epoch [  9/20], Step [150], Loss: 0.2828\n",
      "Epoch [  9/20], Step [200], Loss: 0.3020\n",
      "Epoch [  9/20], Step [250], Loss: 0.3092\n",
      "Epoch [  9/20], Step [300], Loss: 0.3022\n",
      "Epoch [  9/20], Step [350], Loss: 0.2929\n",
      "Epoch [  9/20], Step [400], Loss: 0.2936\n",
      "Epoch [  9/20], Step [450], Loss: 0.2908\n",
      "Epoch [  9/20], Step [500], Loss: 0.3156\n",
      "Epoch [  9/20], Step [550], Loss: 0.3076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:30<00:37,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  9/20], Step [600], Loss: 0.2764\n",
      "Epoch [ 10/20], Step [ 50], Loss: 0.2633\n",
      "Epoch [ 10/20], Step [100], Loss: 0.2800\n",
      "Epoch [ 10/20], Step [150], Loss: 0.2679\n",
      "Epoch [ 10/20], Step [200], Loss: 0.2856\n",
      "Epoch [ 10/20], Step [250], Loss: 0.3111\n",
      "Epoch [ 10/20], Step [300], Loss: 0.3051\n",
      "Epoch [ 10/20], Step [350], Loss: 0.2869\n",
      "Epoch [ 10/20], Step [400], Loss: 0.3070\n",
      "Epoch [ 10/20], Step [450], Loss: 0.2814\n",
      "Epoch [ 10/20], Step [500], Loss: 0.3107\n",
      "Epoch [ 10/20], Step [550], Loss: 0.2810\n",
      "Epoch [ 10/20], Step [600], Loss: 0.2870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:33<00:33,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 11/20], Step [ 50], Loss: 0.2761\n",
      "Epoch [ 11/20], Step [100], Loss: 0.2638\n",
      "Epoch [ 11/20], Step [150], Loss: 0.2783\n",
      "Epoch [ 11/20], Step [200], Loss: 0.2889\n",
      "Epoch [ 11/20], Step [250], Loss: 0.2744\n",
      "Epoch [ 11/20], Step [300], Loss: 0.2763\n",
      "Epoch [ 11/20], Step [350], Loss: 0.2917\n",
      "Epoch [ 11/20], Step [400], Loss: 0.2940\n",
      "Epoch [ 11/20], Step [450], Loss: 0.2893\n",
      "Epoch [ 11/20], Step [500], Loss: 0.3029\n",
      "Epoch [ 11/20], Step [550], Loss: 0.2877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:36<00:29,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 11/20], Step [600], Loss: 0.2713\n",
      "Epoch [ 12/20], Step [ 50], Loss: 0.2751\n",
      "Epoch [ 12/20], Step [100], Loss: 0.2670\n",
      "Epoch [ 12/20], Step [150], Loss: 0.2638\n",
      "Epoch [ 12/20], Step [200], Loss: 0.2705\n",
      "Epoch [ 12/20], Step [250], Loss: 0.2731\n",
      "Epoch [ 12/20], Step [300], Loss: 0.2814\n",
      "Epoch [ 12/20], Step [350], Loss: 0.2913\n",
      "Epoch [ 12/20], Step [400], Loss: 0.2764\n",
      "Epoch [ 12/20], Step [450], Loss: 0.2802\n",
      "Epoch [ 12/20], Step [500], Loss: 0.2700\n",
      "Epoch [ 12/20], Step [550], Loss: 0.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:40<00:25,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 12/20], Step [600], Loss: 0.2828\n",
      "Epoch [ 13/20], Step [ 50], Loss: 0.2442\n",
      "Epoch [ 13/20], Step [100], Loss: 0.2542\n",
      "Epoch [ 13/20], Step [150], Loss: 0.2368\n",
      "Epoch [ 13/20], Step [200], Loss: 0.2637\n",
      "Epoch [ 13/20], Step [250], Loss: 0.2509\n",
      "Epoch [ 13/20], Step [300], Loss: 0.2331\n",
      "Epoch [ 13/20], Step [350], Loss: 0.2499\n",
      "Epoch [ 13/20], Step [400], Loss: 0.2437\n",
      "Epoch [ 13/20], Step [450], Loss: 0.2245\n",
      "Epoch [ 13/20], Step [500], Loss: 0.2237\n",
      "Epoch [ 13/20], Step [550], Loss: 0.2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:43<00:23,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 13/20], Step [600], Loss: 0.2492\n",
      "Epoch [ 14/20], Step [ 50], Loss: 0.2397\n",
      "Epoch [ 14/20], Step [100], Loss: 0.2490\n",
      "Epoch [ 14/20], Step [150], Loss: 0.2361\n",
      "Epoch [ 14/20], Step [200], Loss: 0.2373\n",
      "Epoch [ 14/20], Step [250], Loss: 0.2340\n",
      "Epoch [ 14/20], Step [300], Loss: 0.2404\n",
      "Epoch [ 14/20], Step [350], Loss: 0.2446\n",
      "Epoch [ 14/20], Step [400], Loss: 0.2324\n",
      "Epoch [ 14/20], Step [450], Loss: 0.2450\n",
      "Epoch [ 14/20], Step [500], Loss: 0.2293\n",
      "Epoch [ 14/20], Step [550], Loss: 0.2425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:46<00:19,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 14/20], Step [600], Loss: 0.2358\n",
      "Epoch [ 15/20], Step [ 50], Loss: 0.2369\n",
      "Epoch [ 15/20], Step [100], Loss: 0.2281\n",
      "Epoch [ 15/20], Step [150], Loss: 0.2387\n",
      "Epoch [ 15/20], Step [200], Loss: 0.2541\n",
      "Epoch [ 15/20], Step [250], Loss: 0.2297\n",
      "Epoch [ 15/20], Step [300], Loss: 0.2461\n",
      "Epoch [ 15/20], Step [350], Loss: 0.2391\n",
      "Epoch [ 15/20], Step [400], Loss: 0.2310\n",
      "Epoch [ 15/20], Step [450], Loss: 0.2541\n",
      "Epoch [ 15/20], Step [500], Loss: 0.2120\n",
      "Epoch [ 15/20], Step [550], Loss: 0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:49<00:16,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 15/20], Step [600], Loss: 0.2411\n",
      "Epoch [ 16/20], Step [ 50], Loss: 0.2178\n",
      "Epoch [ 16/20], Step [100], Loss: 0.2356\n",
      "Epoch [ 16/20], Step [150], Loss: 0.2400\n",
      "Epoch [ 16/20], Step [200], Loss: 0.2294\n",
      "Epoch [ 16/20], Step [250], Loss: 0.2301\n",
      "Epoch [ 16/20], Step [300], Loss: 0.2460\n",
      "Epoch [ 16/20], Step [350], Loss: 0.2369\n",
      "Epoch [ 16/20], Step [400], Loss: 0.2480\n",
      "Epoch [ 16/20], Step [450], Loss: 0.2321\n",
      "Epoch [ 16/20], Step [500], Loss: 0.2343\n",
      "Epoch [ 16/20], Step [550], Loss: 0.2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:53<00:13,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 16/20], Step [600], Loss: 0.2401\n",
      "Epoch [ 17/20], Step [ 50], Loss: 0.2346\n",
      "Epoch [ 17/20], Step [100], Loss: 0.2499\n",
      "Epoch [ 17/20], Step [150], Loss: 0.2392\n",
      "Epoch [ 17/20], Step [200], Loss: 0.2202\n",
      "Epoch [ 17/20], Step [250], Loss: 0.2279\n",
      "Epoch [ 17/20], Step [300], Loss: 0.2302\n",
      "Epoch [ 17/20], Step [350], Loss: 0.2368\n",
      "Epoch [ 17/20], Step [400], Loss: 0.2309\n",
      "Epoch [ 17/20], Step [450], Loss: 0.2311\n",
      "Epoch [ 17/20], Step [500], Loss: 0.2420\n",
      "Epoch [ 17/20], Step [550], Loss: 0.2274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:56<00:09,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 17/20], Step [600], Loss: 0.2354\n",
      "Epoch [ 18/20], Step [ 50], Loss: 0.2272\n",
      "Epoch [ 18/20], Step [100], Loss: 0.2216\n",
      "Epoch [ 18/20], Step [150], Loss: 0.2292\n",
      "Epoch [ 18/20], Step [200], Loss: 0.2569\n",
      "Epoch [ 18/20], Step [250], Loss: 0.2417\n",
      "Epoch [ 18/20], Step [300], Loss: 0.2322\n",
      "Epoch [ 18/20], Step [350], Loss: 0.2471\n",
      "Epoch [ 18/20], Step [400], Loss: 0.2136\n",
      "Epoch [ 18/20], Step [450], Loss: 0.2480\n",
      "Epoch [ 18/20], Step [500], Loss: 0.2280\n",
      "Epoch [ 18/20], Step [550], Loss: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:59<00:06,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 18/20], Step [600], Loss: 0.2335\n",
      "Epoch [ 19/20], Step [ 50], Loss: 0.2304\n",
      "Epoch [ 19/20], Step [100], Loss: 0.2388\n",
      "Epoch [ 19/20], Step [150], Loss: 0.2228\n",
      "Epoch [ 19/20], Step [200], Loss: 0.2202\n",
      "Epoch [ 19/20], Step [250], Loss: 0.2293\n",
      "Epoch [ 19/20], Step [300], Loss: 0.2403\n",
      "Epoch [ 19/20], Step [350], Loss: 0.2344\n",
      "Epoch [ 19/20], Step [400], Loss: 0.2354\n",
      "Epoch [ 19/20], Step [450], Loss: 0.2344\n",
      "Epoch [ 19/20], Step [500], Loss: 0.2139\n",
      "Epoch [ 19/20], Step [550], Loss: 0.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [01:03<00:03,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 19/20], Step [600], Loss: 0.2239\n",
      "Epoch [ 20/20], Step [ 50], Loss: 0.2443\n",
      "Epoch [ 20/20], Step [100], Loss: 0.2353\n",
      "Epoch [ 20/20], Step [150], Loss: 0.2212\n",
      "Epoch [ 20/20], Step [200], Loss: 0.2222\n",
      "Epoch [ 20/20], Step [250], Loss: 0.2272\n",
      "Epoch [ 20/20], Step [300], Loss: 0.2338\n",
      "Epoch [ 20/20], Step [350], Loss: 0.2264\n",
      "Epoch [ 20/20], Step [400], Loss: 0.2293\n",
      "Epoch [ 20/20], Step [450], Loss: 0.2134\n",
      "Epoch [ 20/20], Step [500], Loss: 0.2300\n",
      "Epoch [ 20/20], Step [550], Loss: 0.2269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:06<00:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 20/20], Step [600], Loss: 0.2269\n",
      "Standard Training completed in 66.66 seconds\n",
      "[STANDARD ACCURACY TEST]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Accuracy: 0.8834\n",
      "[ROBUST ACCURACY TEST - PGD ε=0.1]\n",
      "Robust Accuracy (PGD ε=0.1): 0.0049\n",
      "\n",
      "============================================================\n",
      "IBP ROBUST TRAINING\n",
      "============================================================\n",
      "[IBP TRAINING - Following Paper Protocol]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/20], Step [ 50], Loss: 2.3036, CE: 2.3030, Robust: 2.7552, ε: 0.0008, κ: 0.998\n",
      "Epoch [  1/20], Step [100], Loss: 2.2906, CE: 2.2863, Robust: 3.6439, ε: 0.0017, κ: 0.996\n",
      "Epoch [  1/20], Step [150], Loss: 2.2092, CE: 2.1980, Robust: 4.3338, ε: 0.0025, κ: 0.994\n",
      "Epoch [  1/20], Step [200], Loss: 1.9065, CE: 1.8854, Robust: 4.7602, ε: 0.0033, κ: 0.992\n",
      "Epoch [  1/20], Step [250], Loss: 1.4187, CE: 1.3820, Robust: 5.2863, ε: 0.0042, κ: 0.990\n",
      "Epoch [  1/20], Step [300], Loss: 1.0805, CE: 1.0207, Robust: 6.2327, ε: 0.0050, κ: 0.988\n",
      "Epoch [  1/20], Step [350], Loss: 0.9588, CE: 0.8728, Robust: 7.2229, ε: 0.0058, κ: 0.985\n",
      "Epoch [  1/20], Step [400], Loss: 0.8979, CE: 0.7856, Robust: 7.9708, ε: 0.0067, κ: 0.983\n",
      "Epoch [  1/20], Step [450], Loss: 0.8898, CE: 0.7519, Robust: 8.5375, ε: 0.0075, κ: 0.981\n",
      "Epoch [  1/20], Step [500], Loss: 0.8806, CE: 0.7209, Robust: 8.7976, ε: 0.0083, κ: 0.979\n",
      "Epoch [  1/20], Step [550], Loss: 0.8875, CE: 0.7069, Robust: 8.9703, ε: 0.0092, κ: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:20<06:28, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/20], Step [600], Loss: 0.8519, CE: 0.6590, Robust: 8.7167, ε: 0.0100, κ: 0.975\n",
      "Epoch [  2/20], Step [ 50], Loss: 0.8479, CE: 0.6428, Robust: 8.5262, ε: 0.0108, κ: 0.973\n",
      "Epoch [  2/20], Step [100], Loss: 0.8417, CE: 0.6315, Robust: 8.1128, ε: 0.0117, κ: 0.971\n",
      "Epoch [  2/20], Step [150], Loss: 0.8501, CE: 0.6367, Robust: 7.7088, ε: 0.0125, κ: 0.969\n",
      "Epoch [  2/20], Step [200], Loss: 0.8296, CE: 0.6171, Robust: 7.2060, ε: 0.0133, κ: 0.967\n",
      "Epoch [  2/20], Step [250], Loss: 0.8503, CE: 0.6371, Robust: 6.8455, ε: 0.0141, κ: 0.965\n",
      "Epoch [  2/20], Step [300], Loss: 0.8759, CE: 0.6648, Robust: 6.4627, ε: 0.0150, κ: 0.963\n",
      "Epoch [  2/20], Step [350], Loss: 0.8381, CE: 0.6322, Robust: 5.9800, ε: 0.0158, κ: 0.960\n",
      "Epoch [  2/20], Step [400], Loss: 0.8042, CE: 0.6016, Robust: 5.5911, ε: 0.0167, κ: 0.958\n",
      "Epoch [  2/20], Step [450], Loss: 0.8071, CE: 0.6062, Robust: 5.3148, ε: 0.0175, κ: 0.956\n",
      "Epoch [  2/20], Step [500], Loss: 0.8012, CE: 0.6030, Robust: 5.0303, ε: 0.0183, κ: 0.954\n",
      "Epoch [  2/20], Step [550], Loss: 0.7823, CE: 0.5855, Robust: 4.7881, ε: 0.0192, κ: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:40<06:05, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  2/20], Step [600], Loss: 0.8031, CE: 0.6056, Robust: 4.6402, ε: 0.0200, κ: 0.950\n",
      "Epoch [  3/20], Step [ 50], Loss: 0.7787, CE: 0.5844, Robust: 4.3945, ε: 0.0208, κ: 0.948\n",
      "Epoch [  3/20], Step [100], Loss: 0.7965, CE: 0.6045, Robust: 4.2205, ε: 0.0217, κ: 0.946\n",
      "Epoch [  3/20], Step [150], Loss: 0.7925, CE: 0.6043, Robust: 4.0154, ε: 0.0225, κ: 0.944\n",
      "Epoch [  3/20], Step [200], Loss: 0.7689, CE: 0.5842, Robust: 3.8104, ε: 0.0233, κ: 0.942\n",
      "Epoch [  3/20], Step [250], Loss: 0.7982, CE: 0.6130, Robust: 3.7349, ε: 0.0242, κ: 0.940\n",
      "Epoch [  3/20], Step [300], Loss: 0.7788, CE: 0.5970, Robust: 3.5570, ε: 0.0250, κ: 0.938\n",
      "Epoch [  3/20], Step [350], Loss: 0.7573, CE: 0.5749, Robust: 3.4465, ε: 0.0258, κ: 0.935\n",
      "Epoch [  3/20], Step [400], Loss: 0.7750, CE: 0.5874, Robust: 3.4464, ε: 0.0267, κ: 0.933\n",
      "Epoch [  3/20], Step [450], Loss: 0.7518, CE: 0.5684, Robust: 3.2782, ε: 0.0275, κ: 0.931\n",
      "Epoch [  3/20], Step [500], Loss: 0.7579, CE: 0.5768, Robust: 3.1729, ε: 0.0283, κ: 0.929\n",
      "Epoch [  3/20], Step [550], Loss: 0.8003, CE: 0.6153, Robust: 3.1904, ε: 0.0291, κ: 0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:55<05:04, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  3/20], Step [600], Loss: 0.7826, CE: 0.5979, Robust: 3.0965, ε: 0.0300, κ: 0.925\n",
      "Epoch [  4/20], Step [ 50], Loss: 0.7593, CE: 0.5779, Robust: 2.9650, ε: 0.0308, κ: 0.923\n",
      "Epoch [  4/20], Step [100], Loss: 0.7647, CE: 0.5775, Robust: 2.9732, ε: 0.0317, κ: 0.921\n",
      "Epoch [  4/20], Step [150], Loss: 0.7659, CE: 0.5784, Robust: 2.9166, ε: 0.0325, κ: 0.919\n",
      "Epoch [  4/20], Step [200], Loss: 0.7660, CE: 0.5793, Robust: 2.8477, ε: 0.0333, κ: 0.917\n",
      "Epoch [  4/20], Step [250], Loss: 0.7811, CE: 0.5930, Robust: 2.8231, ε: 0.0342, κ: 0.915\n",
      "Epoch [  4/20], Step [300], Loss: 0.7632, CE: 0.5743, Robust: 2.7598, ε: 0.0350, κ: 0.913\n",
      "Epoch [  4/20], Step [350], Loss: 0.7939, CE: 0.6060, Robust: 2.7288, ε: 0.0358, κ: 0.910\n",
      "Epoch [  4/20], Step [400], Loss: 0.7848, CE: 0.5928, Robust: 2.7121, ε: 0.0367, κ: 0.908\n",
      "Epoch [  4/20], Step [450], Loss: 0.7575, CE: 0.5693, Robust: 2.6002, ε: 0.0375, κ: 0.906\n",
      "Epoch [  4/20], Step [500], Loss: 0.7717, CE: 0.5803, Robust: 2.6001, ε: 0.0383, κ: 0.904\n",
      "Epoch [  4/20], Step [550], Loss: 0.7656, CE: 0.5743, Robust: 2.5496, ε: 0.0392, κ: 0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:12<04:40, 17.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  4/20], Step [600], Loss: 0.7719, CE: 0.5787, Robust: 2.5308, ε: 0.0400, κ: 0.900\n",
      "Epoch [  5/20], Step [ 50], Loss: 0.7602, CE: 0.5663, Robust: 2.4855, ε: 0.0408, κ: 0.898\n",
      "Epoch [  5/20], Step [100], Loss: 0.7808, CE: 0.5877, Robust: 2.4605, ε: 0.0416, κ: 0.896\n",
      "Epoch [  5/20], Step [150], Loss: 0.7770, CE: 0.5791, Robust: 2.4608, ε: 0.0425, κ: 0.894\n",
      "Epoch [  5/20], Step [200], Loss: 0.7863, CE: 0.5855, Robust: 2.4579, ε: 0.0433, κ: 0.892\n",
      "Epoch [  5/20], Step [250], Loss: 0.7836, CE: 0.5847, Robust: 2.4036, ε: 0.0442, κ: 0.890\n",
      "Epoch [  5/20], Step [300], Loss: 0.7901, CE: 0.5912, Robust: 2.3767, ε: 0.0450, κ: 0.888\n",
      "Epoch [  5/20], Step [350], Loss: 0.7906, CE: 0.5858, Robust: 2.3899, ε: 0.0458, κ: 0.885\n",
      "Epoch [  5/20], Step [400], Loss: 0.7966, CE: 0.5921, Robust: 2.3612, ε: 0.0467, κ: 0.883\n",
      "Epoch [  5/20], Step [450], Loss: 0.7611, CE: 0.5605, Robust: 2.2647, ε: 0.0475, κ: 0.881\n",
      "Epoch [  5/20], Step [500], Loss: 0.8066, CE: 0.5964, Robust: 2.3515, ε: 0.0483, κ: 0.879\n",
      "Epoch [  5/20], Step [550], Loss: 0.7980, CE: 0.5900, Robust: 2.2973, ε: 0.0491, κ: 0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:33<04:38, 18.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  5/20], Step [600], Loss: 0.7891, CE: 0.5771, Robust: 2.2879, ε: 0.0500, κ: 0.875\n",
      "Epoch [  6/20], Step [ 50], Loss: 0.7918, CE: 0.5828, Robust: 2.2416, ε: 0.0508, κ: 0.873\n",
      "Epoch [  6/20], Step [100], Loss: 0.7905, CE: 0.5808, Robust: 2.2173, ε: 0.0517, κ: 0.871\n",
      "Epoch [  6/20], Step [150], Loss: 0.8088, CE: 0.5948, Robust: 2.2380, ε: 0.0525, κ: 0.869\n",
      "Epoch [  6/20], Step [200], Loss: 0.7998, CE: 0.5860, Robust: 2.2026, ε: 0.0533, κ: 0.867\n",
      "Epoch [  6/20], Step [250], Loss: 0.8127, CE: 0.5909, Robust: 2.2414, ε: 0.0542, κ: 0.865\n",
      "Epoch [  6/20], Step [300], Loss: 0.7928, CE: 0.5698, Robust: 2.2041, ε: 0.0550, κ: 0.863\n",
      "Epoch [  6/20], Step [350], Loss: 0.8492, CE: 0.6151, Robust: 2.3048, ε: 0.0558, κ: 0.860\n",
      "Epoch [  6/20], Step [400], Loss: 0.8096, CE: 0.5887, Robust: 2.1597, ε: 0.0567, κ: 0.858\n",
      "Epoch [  6/20], Step [450], Loss: 0.8232, CE: 0.5901, Robust: 2.2235, ε: 0.0575, κ: 0.856\n",
      "Epoch [  6/20], Step [500], Loss: 0.8341, CE: 0.5995, Robust: 2.2198, ε: 0.0583, κ: 0.854\n",
      "Epoch [  6/20], Step [550], Loss: 0.8329, CE: 0.6003, Robust: 2.1841, ε: 0.0592, κ: 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:52<04:26, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  6/20], Step [600], Loss: 0.8223, CE: 0.5902, Robust: 2.1484, ε: 0.0600, κ: 0.850\n",
      "Epoch [  7/20], Step [ 50], Loss: 0.8178, CE: 0.5839, Robust: 2.1331, ε: 0.0608, κ: 0.848\n",
      "Epoch [  7/20], Step [100], Loss: 0.8121, CE: 0.5687, Robust: 2.1587, ε: 0.0617, κ: 0.846\n",
      "Epoch [  7/20], Step [150], Loss: 0.8214, CE: 0.5811, Robust: 2.1294, ε: 0.0625, κ: 0.844\n",
      "Epoch [  7/20], Step [200], Loss: 0.8437, CE: 0.5941, Robust: 2.1817, ε: 0.0633, κ: 0.842\n",
      "Epoch [  7/20], Step [250], Loss: 0.8453, CE: 0.5977, Robust: 2.1512, ε: 0.0641, κ: 0.840\n",
      "Epoch [  7/20], Step [300], Loss: 0.8693, CE: 0.6159, Robust: 2.1858, ε: 0.0650, κ: 0.838\n",
      "Epoch [  7/20], Step [350], Loss: 0.8519, CE: 0.5998, Robust: 2.1417, ε: 0.0658, κ: 0.835\n",
      "Epoch [  7/20], Step [400], Loss: 0.8876, CE: 0.6281, Robust: 2.1947, ε: 0.0667, κ: 0.833\n",
      "Epoch [  7/20], Step [450], Loss: 0.8683, CE: 0.6063, Robust: 2.1692, ε: 0.0675, κ: 0.831\n",
      "Epoch [  7/20], Step [500], Loss: 0.8625, CE: 0.5965, Robust: 2.1631, ε: 0.0683, κ: 0.829\n",
      "Epoch [  7/20], Step [550], Loss: 0.9043, CE: 0.6282, Robust: 2.2347, ε: 0.0692, κ: 0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:13<04:13, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  7/20], Step [600], Loss: 0.8895, CE: 0.6239, Robust: 2.1509, ε: 0.0700, κ: 0.825\n",
      "Epoch [  8/20], Step [ 50], Loss: 0.8820, CE: 0.6127, Robust: 2.1427, ε: 0.0708, κ: 0.823\n",
      "Epoch [  8/20], Step [100], Loss: 0.8781, CE: 0.6060, Robust: 2.1335, ε: 0.0717, κ: 0.821\n",
      "Epoch [  8/20], Step [150], Loss: 0.8664, CE: 0.5884, Robust: 2.1310, ε: 0.0725, κ: 0.819\n",
      "Epoch [  8/20], Step [200], Loss: 0.8999, CE: 0.6197, Robust: 2.1573, ε: 0.0733, κ: 0.817\n",
      "Epoch [  8/20], Step [250], Loss: 0.8990, CE: 0.6159, Robust: 2.1514, ε: 0.0742, κ: 0.815\n",
      "Epoch [  8/20], Step [300], Loss: 0.8804, CE: 0.5925, Robust: 2.1368, ε: 0.0750, κ: 0.813\n",
      "Epoch [  8/20], Step [350], Loss: 0.8984, CE: 0.6085, Robust: 2.1464, ε: 0.0758, κ: 0.810\n",
      "Epoch [  8/20], Step [400], Loss: 0.9193, CE: 0.6241, Robust: 2.1726, ε: 0.0766, κ: 0.808\n",
      "Epoch [  8/20], Step [450], Loss: 0.9098, CE: 0.6170, Robust: 2.1366, ε: 0.0775, κ: 0.806\n",
      "Epoch [  8/20], Step [500], Loss: 0.9154, CE: 0.6161, Robust: 2.1523, ε: 0.0783, κ: 0.804\n",
      "Epoch [  8/20], Step [550], Loss: 0.9045, CE: 0.6051, Robust: 2.1261, ε: 0.0791, κ: 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:27<03:31, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  8/20], Step [600], Loss: 0.9481, CE: 0.6406, Robust: 2.1860, ε: 0.0800, κ: 0.800\n",
      "Epoch [  9/20], Step [ 50], Loss: 0.9571, CE: 0.6490, Robust: 2.1817, ε: 0.0808, κ: 0.798\n",
      "Epoch [  9/20], Step [100], Loss: 0.9378, CE: 0.6321, Robust: 2.1373, ε: 0.0817, κ: 0.796\n",
      "Epoch [  9/20], Step [150], Loss: 0.9428, CE: 0.6305, Robust: 2.1524, ε: 0.0825, κ: 0.794\n",
      "Epoch [  9/20], Step [200], Loss: 0.9314, CE: 0.6163, Robust: 2.1365, ε: 0.0833, κ: 0.792\n",
      "Epoch [  9/20], Step [250], Loss: 0.9354, CE: 0.6161, Robust: 2.1415, ε: 0.0842, κ: 0.790\n",
      "Epoch [  9/20], Step [300], Loss: 0.9337, CE: 0.6116, Robust: 2.1350, ε: 0.0850, κ: 0.788\n",
      "Epoch [  9/20], Step [350], Loss: 0.9627, CE: 0.6232, Robust: 2.2130, ε: 0.0858, κ: 0.785\n",
      "Epoch [  9/20], Step [400], Loss: 0.9601, CE: 0.6242, Robust: 2.1819, ε: 0.0867, κ: 0.783\n",
      "Epoch [  9/20], Step [450], Loss: 0.9683, CE: 0.6309, Robust: 2.1805, ε: 0.0875, κ: 0.781\n",
      "Epoch [  9/20], Step [500], Loss: 0.9697, CE: 0.6301, Robust: 2.1752, ε: 0.0883, κ: 0.779\n",
      "Epoch [  9/20], Step [550], Loss: 0.9868, CE: 0.6409, Robust: 2.2000, ε: 0.0892, κ: 0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:45<03:16, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  9/20], Step [600], Loss: 0.9748, CE: 0.6344, Robust: 2.1544, ε: 0.0900, κ: 0.775\n",
      "Epoch [ 10/20], Step [ 50], Loss: 0.9813, CE: 0.6310, Robust: 2.1810, ε: 0.0908, κ: 0.773\n",
      "Epoch [ 10/20], Step [100], Loss: 0.9818, CE: 0.6323, Robust: 2.1645, ε: 0.0917, κ: 0.771\n",
      "Epoch [ 10/20], Step [150], Loss: 0.9912, CE: 0.6347, Robust: 2.1836, ε: 0.0925, κ: 0.769\n",
      "Epoch [ 10/20], Step [200], Loss: 1.0144, CE: 0.6476, Robust: 2.2269, ε: 0.0933, κ: 0.767\n",
      "Epoch [ 10/20], Step [250], Loss: 1.0125, CE: 0.6433, Robust: 2.2189, ε: 0.0942, κ: 0.765\n",
      "Epoch [ 10/20], Step [300], Loss: 1.0051, CE: 0.6343, Robust: 2.2027, ε: 0.0950, κ: 0.763\n",
      "Epoch [ 10/20], Step [350], Loss: 1.0082, CE: 0.6377, Robust: 2.1910, ε: 0.0958, κ: 0.760\n",
      "Epoch [ 10/20], Step [400], Loss: 1.0034, CE: 0.6328, Robust: 2.1731, ε: 0.0967, κ: 0.758\n",
      "Epoch [ 10/20], Step [450], Loss: 1.0232, CE: 0.6401, Robust: 2.2187, ε: 0.0975, κ: 0.756\n",
      "Epoch [ 10/20], Step [500], Loss: 1.0418, CE: 0.6557, Robust: 2.2333, ε: 0.0983, κ: 0.754\n",
      "Epoch [ 10/20], Step [550], Loss: 1.0177, CE: 0.6372, Robust: 2.1784, ε: 0.0992, κ: 0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:05<03:05, 18.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 10/20], Step [600], Loss: 1.0643, CE: 0.6746, Robust: 2.2403, ε: 0.1000, κ: 0.750\n",
      "Epoch [ 11/20], Step [ 50], Loss: 1.0399, CE: 0.6512, Robust: 2.1996, ε: 0.1000, κ: 0.748\n",
      "Epoch [ 11/20], Step [100], Loss: 1.0477, CE: 0.6546, Robust: 2.2078, ε: 0.1000, κ: 0.746\n",
      "Epoch [ 11/20], Step [150], Loss: 1.0230, CE: 0.6323, Robust: 2.1635, ε: 0.1000, κ: 0.744\n",
      "Epoch [ 11/20], Step [200], Loss: 1.0590, CE: 0.6529, Robust: 2.2311, ε: 0.1000, κ: 0.742\n",
      "Epoch [ 11/20], Step [250], Loss: 1.0535, CE: 0.6556, Robust: 2.1896, ε: 0.1000, κ: 0.740\n",
      "Epoch [ 11/20], Step [300], Loss: 1.0725, CE: 0.6744, Robust: 2.1972, ε: 0.1000, κ: 0.738\n",
      "Epoch [ 11/20], Step [350], Loss: 1.0181, CE: 0.6275, Robust: 2.1098, ε: 0.1000, κ: 0.735\n",
      "Epoch [ 11/20], Step [400], Loss: 1.0609, CE: 0.6576, Robust: 2.1763, ε: 0.1000, κ: 0.733\n",
      "Epoch [ 11/20], Step [450], Loss: 1.0473, CE: 0.6451, Robust: 2.1476, ε: 0.1000, κ: 0.731\n",
      "Epoch [ 11/20], Step [500], Loss: 1.0708, CE: 0.6671, Robust: 2.1638, ε: 0.1000, κ: 0.729\n",
      "Epoch [ 11/20], Step [550], Loss: 1.0762, CE: 0.6674, Robust: 2.1710, ε: 0.1000, κ: 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:25<02:50, 18.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 11/20], Step [600], Loss: 1.0776, CE: 0.6812, Robust: 2.1282, ε: 0.1000, κ: 0.725\n",
      "Epoch [ 12/20], Step [ 50], Loss: 1.0539, CE: 0.6550, Robust: 2.1005, ε: 0.1000, κ: 0.723\n",
      "Epoch [ 12/20], Step [100], Loss: 1.0665, CE: 0.6606, Robust: 2.1204, ε: 0.1000, κ: 0.721\n",
      "Epoch [ 12/20], Step [150], Loss: 1.0606, CE: 0.6520, Robust: 2.1103, ε: 0.1000, κ: 0.719\n",
      "Epoch [ 12/20], Step [200], Loss: 1.0540, CE: 0.6505, Robust: 2.0803, ε: 0.1000, κ: 0.717\n",
      "Epoch [ 12/20], Step [250], Loss: 1.0798, CE: 0.6680, Robust: 2.1164, ε: 0.1000, κ: 0.715\n",
      "Epoch [ 12/20], Step [300], Loss: 1.0811, CE: 0.6713, Robust: 2.1022, ε: 0.1000, κ: 0.713\n",
      "Epoch [ 12/20], Step [350], Loss: 1.0611, CE: 0.6554, Robust: 2.0613, ε: 0.1000, κ: 0.710\n",
      "Epoch [ 12/20], Step [400], Loss: 1.0853, CE: 0.6729, Robust: 2.0923, ε: 0.1000, κ: 0.708\n",
      "Epoch [ 12/20], Step [450], Loss: 1.0597, CE: 0.6598, Robust: 2.0258, ε: 0.1000, κ: 0.706\n",
      "Epoch [ 12/20], Step [500], Loss: 1.0920, CE: 0.6660, Robust: 2.1113, ε: 0.1000, κ: 0.704\n",
      "Epoch [ 12/20], Step [550], Loss: 1.0892, CE: 0.6668, Robust: 2.0898, ε: 0.1000, κ: 0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:41<02:24, 18.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 12/20], Step [600], Loss: 1.0864, CE: 0.6668, Robust: 2.0704, ε: 0.1000, κ: 0.700\n",
      "Epoch [ 13/20], Step [ 50], Loss: 1.0618, CE: 0.6546, Robust: 2.0074, ε: 0.1000, κ: 0.698\n",
      "Epoch [ 13/20], Step [100], Loss: 1.0810, CE: 0.6868, Robust: 1.9875, ε: 0.1000, κ: 0.696\n",
      "Epoch [ 13/20], Step [150], Loss: 1.0554, CE: 0.6658, Robust: 1.9423, ε: 0.1000, κ: 0.694\n",
      "Epoch [ 13/20], Step [200], Loss: 1.0649, CE: 0.6684, Robust: 1.9588, ε: 0.1000, κ: 0.692\n",
      "Epoch [ 13/20], Step [250], Loss: 1.0466, CE: 0.6562, Robust: 1.9180, ε: 0.1000, κ: 0.690\n",
      "Epoch [ 13/20], Step [300], Loss: 1.0320, CE: 0.6410, Robust: 1.8965, ε: 0.1000, κ: 0.688\n",
      "Epoch [ 13/20], Step [350], Loss: 1.0442, CE: 0.6460, Robust: 1.9161, ε: 0.1000, κ: 0.685\n",
      "Epoch [ 13/20], Step [400], Loss: 1.0687, CE: 0.6653, Robust: 1.9435, ε: 0.1000, κ: 0.683\n",
      "Epoch [ 13/20], Step [450], Loss: 1.0765, CE: 0.6688, Robust: 1.9520, ε: 0.1000, κ: 0.681\n",
      "Epoch [ 13/20], Step [500], Loss: 1.0708, CE: 0.6596, Robust: 1.9455, ε: 0.1000, κ: 0.679\n",
      "Epoch [ 13/20], Step [550], Loss: 1.0541, CE: 0.6455, Robust: 1.9151, ε: 0.1000, κ: 0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [03:57<02:01, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 13/20], Step [600], Loss: 1.0619, CE: 0.6497, Robust: 1.9222, ε: 0.1000, κ: 0.675\n",
      "Epoch [ 14/20], Step [ 50], Loss: 1.0730, CE: 0.6550, Robust: 1.9371, ε: 0.1000, κ: 0.673\n",
      "Epoch [ 14/20], Step [100], Loss: 1.0635, CE: 0.6474, Robust: 1.9154, ε: 0.1000, κ: 0.671\n",
      "Epoch [ 14/20], Step [150], Loss: 1.0699, CE: 0.6546, Robust: 1.9124, ε: 0.1000, κ: 0.669\n",
      "Epoch [ 14/20], Step [200], Loss: 1.0968, CE: 0.6712, Robust: 1.9521, ε: 0.1000, κ: 0.667\n",
      "Epoch [ 14/20], Step [250], Loss: 1.0729, CE: 0.6465, Robust: 1.9218, ε: 0.1000, κ: 0.665\n",
      "Epoch [ 14/20], Step [300], Loss: 1.0961, CE: 0.6680, Robust: 1.9404, ε: 0.1000, κ: 0.663\n",
      "Epoch [ 14/20], Step [350], Loss: 1.0780, CE: 0.6488, Robust: 1.9168, ε: 0.1000, κ: 0.660\n",
      "Epoch [ 14/20], Step [400], Loss: 1.0882, CE: 0.6590, Robust: 1.9189, ε: 0.1000, κ: 0.658\n",
      "Epoch [ 14/20], Step [450], Loss: 1.1165, CE: 0.6711, Robust: 1.9707, ε: 0.1000, κ: 0.656\n",
      "Epoch [ 14/20], Step [500], Loss: 1.0918, CE: 0.6539, Robust: 1.9240, ε: 0.1000, κ: 0.654\n",
      "Epoch [ 14/20], Step [550], Loss: 1.1128, CE: 0.6688, Robust: 1.9490, ε: 0.1000, κ: 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [04:16<01:47, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 14/20], Step [600], Loss: 1.1059, CE: 0.6611, Robust: 1.9358, ε: 0.1000, κ: 0.650\n",
      "Epoch [ 15/20], Step [ 50], Loss: 1.0989, CE: 0.6614, Robust: 1.9078, ε: 0.1000, κ: 0.648\n",
      "Epoch [ 15/20], Step [100], Loss: 1.1482, CE: 0.6895, Robust: 1.9884, ε: 0.1000, κ: 0.646\n",
      "Epoch [ 15/20], Step [150], Loss: 1.0670, CE: 0.6297, Robust: 1.8609, ε: 0.1000, κ: 0.644\n",
      "Epoch [ 15/20], Step [200], Loss: 1.1061, CE: 0.6611, Robust: 1.9068, ε: 0.1000, κ: 0.642\n",
      "Epoch [ 15/20], Step [250], Loss: 1.1258, CE: 0.6771, Robust: 1.9256, ε: 0.1000, κ: 0.640\n",
      "Epoch [ 15/20], Step [300], Loss: 1.1159, CE: 0.6577, Robust: 1.9253, ε: 0.1000, κ: 0.638\n",
      "Epoch [ 15/20], Step [350], Loss: 1.1248, CE: 0.6621, Robust: 1.9351, ε: 0.1000, κ: 0.635\n",
      "Epoch [ 15/20], Step [400], Loss: 1.1087, CE: 0.6589, Robust: 1.8893, ε: 0.1000, κ: 0.633\n",
      "Epoch [ 15/20], Step [450], Loss: 1.1356, CE: 0.6700, Robust: 1.9363, ε: 0.1000, κ: 0.631\n",
      "Epoch [ 15/20], Step [500], Loss: 1.1256, CE: 0.6660, Robust: 1.9090, ε: 0.1000, κ: 0.629\n",
      "Epoch [ 15/20], Step [550], Loss: 1.1235, CE: 0.6596, Robust: 1.9070, ε: 0.1000, κ: 0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:36<01:32, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 15/20], Step [600], Loss: 1.1393, CE: 0.6653, Robust: 1.9327, ε: 0.1000, κ: 0.625\n",
      "Epoch [ 16/20], Step [ 50], Loss: 1.1174, CE: 0.6603, Robust: 1.8760, ε: 0.1000, κ: 0.623\n",
      "Epoch [ 16/20], Step [100], Loss: 1.1462, CE: 0.6708, Robust: 1.9281, ε: 0.1000, κ: 0.621\n",
      "Epoch [ 16/20], Step [150], Loss: 1.1310, CE: 0.6597, Robust: 1.8994, ε: 0.1000, κ: 0.619\n",
      "Epoch [ 16/20], Step [200], Loss: 1.1578, CE: 0.6801, Robust: 1.9299, ε: 0.1000, κ: 0.617\n",
      "Epoch [ 16/20], Step [250], Loss: 1.1543, CE: 0.6787, Robust: 1.9161, ε: 0.1000, κ: 0.615\n",
      "Epoch [ 16/20], Step [300], Loss: 1.1451, CE: 0.6669, Robust: 1.9044, ε: 0.1000, κ: 0.613\n",
      "Epoch [ 16/20], Step [350], Loss: 1.1532, CE: 0.6721, Robust: 1.9105, ε: 0.1000, κ: 0.610\n",
      "Epoch [ 16/20], Step [400], Loss: 1.1521, CE: 0.6696, Robust: 1.9048, ε: 0.1000, κ: 0.608\n",
      "Epoch [ 16/20], Step [450], Loss: 1.1576, CE: 0.6669, Robust: 1.9165, ε: 0.1000, κ: 0.606\n",
      "Epoch [ 16/20], Step [500], Loss: 1.1546, CE: 0.6745, Robust: 1.8907, ε: 0.1000, κ: 0.604\n",
      "Epoch [ 16/20], Step [550], Loss: 1.1405, CE: 0.6616, Robust: 1.8684, ε: 0.1000, κ: 0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [04:56<01:16, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 16/20], Step [600], Loss: 1.1598, CE: 0.6685, Robust: 1.9000, ε: 0.1000, κ: 0.600\n",
      "Epoch [ 17/20], Step [ 50], Loss: 1.1551, CE: 0.6683, Robust: 1.8822, ε: 0.1000, κ: 0.598\n",
      "Epoch [ 17/20], Step [100], Loss: 1.1649, CE: 0.6667, Robust: 1.9025, ε: 0.1000, κ: 0.596\n",
      "Epoch [ 17/20], Step [150], Loss: 1.1537, CE: 0.6677, Robust: 1.8673, ε: 0.1000, κ: 0.594\n",
      "Epoch [ 17/20], Step [200], Loss: 1.1950, CE: 0.6938, Robust: 1.9243, ε: 0.1000, κ: 0.592\n",
      "Epoch [ 17/20], Step [250], Loss: 1.1953, CE: 0.6934, Robust: 1.9194, ε: 0.1000, κ: 0.590\n",
      "Epoch [ 17/20], Step [300], Loss: 1.1786, CE: 0.6801, Robust: 1.8917, ε: 0.1000, κ: 0.588\n",
      "Epoch [ 17/20], Step [350], Loss: 1.1835, CE: 0.6805, Robust: 1.8968, ε: 0.1000, κ: 0.585\n",
      "Epoch [ 17/20], Step [400], Loss: 1.1709, CE: 0.6734, Robust: 1.8705, ε: 0.1000, κ: 0.583\n",
      "Epoch [ 17/20], Step [450], Loss: 1.1644, CE: 0.6662, Robust: 1.8590, ε: 0.1000, κ: 0.581\n",
      "Epoch [ 17/20], Step [500], Loss: 1.1729, CE: 0.6728, Robust: 1.8643, ε: 0.1000, κ: 0.579\n",
      "Epoch [ 17/20], Step [550], Loss: 1.1867, CE: 0.6760, Robust: 1.8868, ε: 0.1000, κ: 0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:11<00:52, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 17/20], Step [600], Loss: 1.1907, CE: 0.6817, Robust: 1.8823, ε: 0.1000, κ: 0.575\n",
      "Epoch [ 18/20], Step [ 50], Loss: 1.1859, CE: 0.6754, Robust: 1.8736, ε: 0.1000, κ: 0.573\n",
      "Epoch [ 18/20], Step [100], Loss: 1.1932, CE: 0.6832, Robust: 1.8745, ε: 0.1000, κ: 0.571\n",
      "Epoch [ 18/20], Step [150], Loss: 1.1903, CE: 0.6797, Robust: 1.8666, ε: 0.1000, κ: 0.569\n",
      "Epoch [ 18/20], Step [200], Loss: 1.1769, CE: 0.6662, Robust: 1.8476, ε: 0.1000, κ: 0.567\n",
      "Epoch [ 18/20], Step [250], Loss: 1.2147, CE: 0.6887, Robust: 1.8997, ε: 0.1000, κ: 0.565\n",
      "Epoch [ 18/20], Step [300], Loss: 1.2071, CE: 0.6920, Robust: 1.8724, ε: 0.1000, κ: 0.563\n",
      "Epoch [ 18/20], Step [350], Loss: 1.1990, CE: 0.6817, Robust: 1.8615, ε: 0.1000, κ: 0.560\n",
      "Epoch [ 18/20], Step [400], Loss: 1.2008, CE: 0.6786, Robust: 1.8639, ε: 0.1000, κ: 0.558\n",
      "Epoch [ 18/20], Step [450], Loss: 1.2111, CE: 0.6900, Robust: 1.8671, ε: 0.1000, κ: 0.556\n",
      "Epoch [ 18/20], Step [500], Loss: 1.2086, CE: 0.6847, Robust: 1.8626, ε: 0.1000, κ: 0.554\n",
      "Epoch [ 18/20], Step [550], Loss: 1.2282, CE: 0.6942, Robust: 1.8893, ε: 0.1000, κ: 0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:27<00:34, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 18/20], Step [600], Loss: 1.2263, CE: 0.6940, Robust: 1.8797, ε: 0.1000, κ: 0.550\n",
      "Epoch [ 19/20], Step [ 50], Loss: 1.2138, CE: 0.6870, Robust: 1.8551, ε: 0.1000, κ: 0.548\n",
      "Epoch [ 19/20], Step [100], Loss: 1.2189, CE: 0.6899, Robust: 1.8573, ε: 0.1000, κ: 0.546\n",
      "Epoch [ 19/20], Step [150], Loss: 1.2129, CE: 0.6912, Robust: 1.8373, ε: 0.1000, κ: 0.544\n",
      "Epoch [ 19/20], Step [200], Loss: 1.2012, CE: 0.6775, Robust: 1.8227, ε: 0.1000, κ: 0.542\n",
      "Epoch [ 19/20], Step [250], Loss: 1.2022, CE: 0.6717, Robust: 1.8266, ε: 0.1000, κ: 0.540\n",
      "Epoch [ 19/20], Step [300], Loss: 1.2204, CE: 0.6824, Robust: 1.8483, ε: 0.1000, κ: 0.538\n",
      "Epoch [ 19/20], Step [350], Loss: 1.2214, CE: 0.6870, Robust: 1.8399, ε: 0.1000, κ: 0.535\n",
      "Epoch [ 19/20], Step [400], Loss: 1.2288, CE: 0.6896, Robust: 1.8477, ε: 0.1000, κ: 0.533\n",
      "Epoch [ 19/20], Step [450], Loss: 1.2356, CE: 0.6833, Robust: 1.8642, ε: 0.1000, κ: 0.531\n",
      "Epoch [ 19/20], Step [500], Loss: 1.2226, CE: 0.6838, Robust: 1.8308, ε: 0.1000, κ: 0.529\n",
      "Epoch [ 19/20], Step [550], Loss: 1.2623, CE: 0.7120, Robust: 1.8782, ε: 0.1000, κ: 0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [05:47<00:18, 18.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 19/20], Step [600], Loss: 1.2750, CE: 0.7148, Robust: 1.8968, ε: 0.1000, κ: 0.525\n",
      "Epoch [ 20/20], Step [ 50], Loss: 1.2495, CE: 0.6954, Robust: 1.8595, ε: 0.1000, κ: 0.523\n",
      "Epoch [ 20/20], Step [100], Loss: 1.2502, CE: 0.6852, Robust: 1.8670, ε: 0.1000, κ: 0.521\n",
      "Epoch [ 20/20], Step [150], Loss: 1.2658, CE: 0.7064, Robust: 1.8714, ε: 0.1000, κ: 0.519\n",
      "Epoch [ 20/20], Step [200], Loss: 1.2329, CE: 0.6809, Robust: 1.8254, ε: 0.1000, κ: 0.517\n",
      "Epoch [ 20/20], Step [250], Loss: 1.2680, CE: 0.7093, Robust: 1.8628, ε: 0.1000, κ: 0.515\n",
      "Epoch [ 20/20], Step [300], Loss: 1.2345, CE: 0.6779, Robust: 1.8222, ε: 0.1000, κ: 0.513\n",
      "Epoch [ 20/20], Step [350], Loss: 1.2633, CE: 0.6890, Robust: 1.8645, ε: 0.1000, κ: 0.510\n",
      "Epoch [ 20/20], Step [400], Loss: 1.2732, CE: 0.7036, Robust: 1.8646, ε: 0.1000, κ: 0.508\n",
      "Epoch [ 20/20], Step [450], Loss: 1.2728, CE: 0.7051, Robust: 1.8573, ε: 0.1000, κ: 0.506\n",
      "Epoch [ 20/20], Step [500], Loss: 1.2719, CE: 0.6972, Robust: 1.8587, ε: 0.1000, κ: 0.504\n",
      "Epoch [ 20/20], Step [550], Loss: 1.2412, CE: 0.6719, Robust: 1.8178, ε: 0.1000, κ: 0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:07<00:00, 18.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 20/20], Step [600], Loss: 1.2296, CE: 0.6696, Robust: 1.7920, ε: 0.1000, κ: 0.500\n",
      "IBP Training completed in 367.37 seconds\n",
      "[STANDARD ACCURACY TEST]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Accuracy: 0.7728\n",
      "[ROBUST ACCURACY TEST - PGD ε=0.1]\n",
      "Robust Accuracy (PGD ε=0.1): 0.5037\n",
      "\n",
      "============================================================\n",
      "RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Model           Std Accuracy    Rob Accuracy    Train Time     \n",
      "------------------------------------------------------------\n",
      "Standard        0.8834          0.0049          66.66          s\n",
      "IBP Robust      0.7728          0.5037          367.37         s\n",
      "\n",
      "Robustness Improvement: 49.88%\n",
      "Training Time Ratio (IBP/Standard): 5.51x\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Train standard model\n",
    "print('\\n' + '='*60)\n",
    "print('STANDARD TRAINING')\n",
    "print('='*60)\n",
    "net_standard = IBPNet().to(device)\n",
    "std_train_time = train_standard(net_standard, device, num_epochs=20)\n",
    "std_accuracy = test_standard_accuracy(net_standard, device)\n",
    "std_robust_accuracy = test_robust_accuracy_pgd(net_standard, device, epsilon=0.1)\n",
    "\n",
    "# Train IBP model\n",
    "print('\\n' + '='*60)\n",
    "print('IBP ROBUST TRAINING')\n",
    "print('='*60)\n",
    "net_ibp = IBPNet().to(device)\n",
    "\n",
    "# Build IBP-enabled model\n",
    "factory = BoundModelFactory()\n",
    "net_ibp = factory.build(net_ibp)\n",
    "\n",
    "ibp_train_time = train_ibp(net_ibp, device, num_epochs=20, epsilon_target=0.1)\n",
    "ibp_accuracy = test_standard_accuracy(net_ibp, device)\n",
    "ibp_robust_accuracy = test_robust_accuracy_pgd(net_ibp, device, epsilon=0.1)\n",
    "\n",
    "# Report results\n",
    "print('\\n' + '='*60)\n",
    "print('RESULTS SUMMARY')\n",
    "print('='*60)\n",
    "print(f'\\n{\"Model\":<15} {\"Std Accuracy\":<15} {\"Rob Accuracy\":<15} {\"Train Time\":<15}')\n",
    "print('-'*60)\n",
    "print(f'{\"Standard\":<15} {std_accuracy:<15.4f} {std_robust_accuracy:<15.4f} {std_train_time:<15.2f}s')\n",
    "print(f'{\"IBP Robust\":<15} {ibp_accuracy:<15.4f} {ibp_robust_accuracy:<15.4f} {ibp_train_time:<15.2f}s')\n",
    "print(f'\\nRobustness Improvement: {(ibp_robust_accuracy - std_robust_accuracy)*100:.2f}%')\n",
    "print(f'Training Time Ratio (IBP/Standard): {ibp_train_time/std_train_time:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "681c7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "def verify_with_boundprop(bound_model, test_loader, eps_list, device):\n",
    "    \"\"\"Verify robustness using interval bound propagation.\n",
    "    \n",
    "    Following the example code approach with verification condition:\n",
    "    lower_bound[true_class] > max(upper_bound[other_classes])\n",
    "    \"\"\"\n",
    "    bound_model.eval()\n",
    "    verified_accs = []\n",
    "    results = {}\n",
    "    \n",
    "    for eps in eps_list:\n",
    "        total = 0\n",
    "        verified = 0\n",
    "        \n",
    "        for images, labels in tqdm(test_loader, desc=f'Verifying ε={eps:.3f}'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.view(images.size(0), -1)  # Flatten manually\n",
    "            \n",
    "            # Create L∞ bounds\n",
    "            input_bounds = HyperRectangle.from_eps(images, eps)\n",
    "            \n",
    "            # Interval Bound Propagation\n",
    "            bounds = bound_model.ibp(input_bounds)\n",
    "            lower, upper = bounds.lower, bounds.upper\n",
    "            \n",
    "            # Verification condition: l_i[true] > max(u_i[j] for j != true)\n",
    "            for i in range(images.size(0)):\n",
    "                true = labels[i].item()\n",
    "                l_i = lower[i]\n",
    "                u_i = upper[i]\n",
    "                \n",
    "                # Get max upper bound for incorrect classes\n",
    "                other_classes = torch.arange(10, device=device) != true\n",
    "                max_other_upper = u_i[other_classes].max()\n",
    "                \n",
    "                if l_i[true] > max_other_upper:\n",
    "                    verified += 1\n",
    "                total += 1\n",
    "        \n",
    "        acc = 100.0 * verified / total\n",
    "        verified_accs.append(acc)\n",
    "        results[eps] = {'verified': verified, 'total': total, 'acc': acc}\n",
    "        print(f\"ε={eps:.3f} → Verified accuracy: {acc:.2f}% ({verified}/{total})\")\n",
    "    \n",
    "    return verified_accs, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdea749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c1ce35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFIED ACCURACY EVALUATION (Box Verification with IBP)\n",
      "======================================================================\n",
      "Using device: cuda\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.010:   0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.010: 100%|██████████| 157/157 [00:33<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.010 → Verified accuracy: 74.12% (7412/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.020: 100%|██████████| 157/157 [00:14<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.020 → Verified accuracy: 71.01% (7101/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.030: 100%|██████████| 157/157 [00:33<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.030 → Verified accuracy: 67.66% (6766/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.040: 100%|██████████| 157/157 [00:35<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.040 → Verified accuracy: 64.14% (6414/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.050: 100%|██████████| 157/157 [00:34<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.050 → Verified accuracy: 60.29% (6029/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.060: 100%|██████████| 157/157 [00:38<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.060 → Verified accuracy: 56.44% (5644/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.070: 100%|██████████| 157/157 [00:20<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.070 → Verified accuracy: 52.09% (5209/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.080: 100%|██████████| 157/157 [00:18<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.080 → Verified accuracy: 47.72% (4772/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.090: 100%|██████████| 157/157 [00:37<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.090 → Verified accuracy: 42.83% (4283/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying ε=0.100: 100%|██████████| 157/157 [00:26<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε=0.100 → Verified accuracy: 38.38% (3838/10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute verified accuracy\n",
    "import numpy as np\n",
    "print('\\n' + '='*70)\n",
    "print('VERIFIED ACCURACY EVALUATION (Box Verification with IBP)')\n",
    "print('='*70)\n",
    "\n",
    "eps_list = np.linspace(0.01, 0.1, 10)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}\\n')\n",
    "\n",
    "# Load test data for verification\n",
    "transform, target_transform = construct_transform()\n",
    "test_data = datasets.FashionMNIST('./fashion_data', train=False, download=True,\n",
    "                                    transform=transform, target_transform=target_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n",
    "verified_accs, results = verify_with_boundprop(net_ibp, test_loader, eps_list, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948be933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pensieve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
